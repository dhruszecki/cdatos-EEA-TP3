---
title: "EEA - TP3 - Regresión Lineal"
author: "Darío Hruszecki"
date: "11/28/2020"
output:
  html_document:
    code_folding: "hide"
    number_sections: FALSE
    toc: yes
    toc_depth: '6'
    df_print: paged
  html_notebook:
    theme: spacelab
    toc_depth: 6
    toc: yes
    toc_float: yes
    df_print: paged
---

<a href="https://github.com/dhruszecki/cdatos-EEA-TP3/" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#70B7FD; color:#fff; position: absolute; top: 0; border: 0; left: 0; transform: scale(-1, 1);" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><


<style type="text/css">
html,body {
    height:100%;
}
div.main-container {
  justify-content: center;
  align-items: center;
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
  justify-content:center;
  align-items:center;
  h1, .h1, h2, .h2, h3, .h3 {
    margin-top: 84px;
  }
}
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
.col-md-4 blue {
  display: flex;
  justify-content: center;
  align-items: center;
  background-color: #bdcebe;
  height: 100%
}
.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# EEA - TP3 - Regresíon lineal


```{r message=FALSE}
## LIBRERIAS
library(tidyverse)
library(tidymodels)
library(modelr)

library(corrr)
library(knitr)
library(kableExtra)
library(ggrepel)

library(OneR)
library(rlang)
library(caret)
library(here)
library(ISLR)
library(GGally)
library(pROC)
library(DT)
library(cowplot)
```

```{r}
## RANDOM SEED
set.seed(6719)
```

## DATOS

Dataset del Titanic, obtenido en Kaggle - Titanic: Machine Learning from Disaster. El mismo se encuentra ya particionado en subconjuntos de entrenamiento y testeo.
El diccionario de datos se puede encontrar [aquí](https://www.kaggle.com/c/titanic/data).

## OBJETIVO

Crear un modelo de regresión logística para clasificar si una persona que viajaba a bordo del Titanic sobrevivió o no.

## DATASET DE ENTRENAMIENTO

### Preparación de datos

##### Leer el archivo titanic_complete_train.csv y mostrar su estructura
```{r message=FALSE}
df_complete <- read_csv(here("/ds/titanic_complete_train.csv"))
glimpse(df_complete)
```

```{r}
datatable(df_complete, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

##### Seleccionar las variables PassengerId, Survived, Pclass, Sex, Age, SibSp,Parch, Fare y Embarked.
```{r}
df = df_complete %>%
  select(PassengerId, Survived, Pclass, Sex,Age, SibSp, Parch, Fare, Embarked
  )
glimpse(df)
```

##### Transformar las variables Survived, Pclass y Embarked a factor.
```{r}
df = df %>%
  mutate(Survived = factor(Survived), Pclass = factor(Pclass), Embarked = factor(Embarked))
glimpse(df)
```

##### Realizar un gráfico de ggpairs para las variables Survived, Pclass, Sex, Age y Fare e interpretarlo.
<div class = "row">
  
<div class = "col-md-8">
```{r message=FALSE}
df %>% select(Survived, Pclass, Sex, Age, Fare) %>% 
  ggpairs(aes(color = Survived), progress = FALSE, upper = list(continuous = wrap( "cor",  size = 3,  hjust=0.8,  align_percent=0.15))) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=45,  vjust=0.5), legend.position = "bottom")
```
</div>
<div class = "col-md-4 blue blue">
**General**

* _El número de sobrevivientes parece ser similar en las 3 clases._* 
* _El número de pasajeros de tercera era ampliamente superior al de las otras clases superiores._
* _Hay presencia de outliers para nuestras variables **Fare** y **Age**._

**Sobrevivientes**

* _El número de mujeres es superior al de los hombres._
* _Casi la totalidad de las mujeres de primera y segunda clase_.
* _La mitad de las mujeres de tercera clase_.

**No sobrevivientes**

* _El mayor número de no sobrevivientes se encuentra entre los de la tercera clase._
* _El número de hombres es significativamente superior que el de las mujeres._
* _El rango etario que prevalece es entre 20 y 40 años._
</div>
</div>

##### Mostrar la distribución de clase (Sobrevivientes vs No Sobrevivientes).
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
survival_distribution <- function(data) {
data %>%  group_by(Survived) %>% 
  summarise(sobrevivientes=n()) %>%
  mutate(
    Survived = ifelse(Survived == 0, "Fallecido", "Sobreviviente"),
    porcentaje = (sobrevivientes / sum(sobrevivientes))* 100 
  )
} 

survival_distribution(df)
```
</div>
<div class = "col-md-4 blue blue">
**Observaciones**

* _Hay un total de 891 pasajeros._
* _De los cuales tenemos un 61.61% Fallecidos y un 38.38% Sobrevivientes._
</div>
</div>

##### Dividir al dataset en conjunto de entrenamiento (70% de los datos) y validación (30% de los datos). Volver a analizar la distribución de clase para chequear que sea aproximadamente igual entre ambos conjuntos y respecto a la distribución de clase que obtuvieron para todo el dataset completo.

<div class = "row">
  
<div class = "col-md-8">
```{r message=FALSE}
train_val <- initial_split(df, prop = 0.7, strata = Survived)
train_val
```

```{r message=FALSE}
df_training <- training(train_val)
print(cbind("Dimensiones training:", dim_desc(df_training)))
```

```{r message=FALSE}
df_validation <- testing(train_val)
print(cbind("Dimensiones validación:", dim_desc(df_validation)))
```

```{r message=FALSE}
print(survival_distribution(df_training))
```
```{r message=FALSE}
print(survival_distribution(df_validation))
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _De un total de 891 pasajeros 625 quedan para entrenamiento y 266 para validación_
* _En la partición de entrenamiento la distribución es Fallecidos 61.6% y Sobrevivientes 38.4%_
* _En la partición de validación la distribución es Fallecidos 61.65% y Sobrevivientes 38.35%_
* _Ambas particiones respetan la distribución de clases del dataset completo_
</div>
</div>

### Predicciones

##### Realizar un modelo de regresión logística para predecir la supervivencia en función de Pclass, Sex y Age. Usar solo el dataset de entrenamiento.
<div class = "row">
<div class = "col-md-8">
```{r}
model_class_sex_age <- glm(Survived ~ Pclass + Sex + Age, data = df_training, family = 'binomial')

tidy_mcsa = tidy(model_class_sex_age)
tidy_mcsa
```
</div>
<div class = "col-md-4 blue">
**Interpretación de los coeficientes**

* _Todos los coeficientes son estadísticamente significativos._
* _Cada coeficiente indica en que factor aumenta o disminuye (dependiendo de si positivo o negativo) la probabilidad de sobrevivir de un pasajero tal que se mantengan las otras variables constantes._
* _Según **Intercept**, aumenta en un factor de 3.53234387 para un pasajero recien nacido (edad=0), de sexo femenino (basal) y que pertenece a primera clase (basal)._
* _Según **Pclass2**, disminuyen en un factor de 1.19745943 para un pasajero que pertenece a segunda clase._
* _Según **Pclass3**, disminuyen en un factor de 2.48918143 para un pasajero que pertenece a tercera clase._
* _Según **Sexmale**, disminuyen en un factor de 2.43509235 para un pasajero que es hombre._
* _Según **Age**, disminuyen en un factor de 0.03328677, si hay un  incremento de un de un año en la edad._
</div>
</div>

##### ¿Quién tiene una mayor probabilidad de supervivencia? Rose que es una mujer de 17 años que viaja en primera clase o Jack que es un hombre de 20 años viajando en tercera clase.
<div class="blue">
Rose, siendo mujer y viajando en primera clase, tiene mayores probabilidades de sobrevivir que Jack, que era hombre y viajaba en tercera.
</div>

### Generación de modelos

##### Generar 3 modelos de regresión logística sobre el dataset de entrenamiento utilizando diferentes combinaciones de variables. Al menos dos modelos deben ser multivariados
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
formulas_logit <- formulas(
  .response = ~ Survived,
  pclass_sex_age = ~ Pclass + Sex + Age,
  pclass_sex_age_fare = ~ Pclass + Sex + Age + Fare,
  pclass_sex_age_sibsp_parch = ~ Pclass + Sex + Age + SibSp + Parch,
  pclass_age_fare = ~ Pclass + Age + Fare)

formulas_logit
```

```{r message=FALSE}
models <- tibble(formulas_logit) %>%
  mutate(model = names(formulas_logit),
    expression = paste(formulas_logit),
    mod = map(formulas_logit, ~glm(., family = 'binomial', data = df_training)))

models
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _Creamos las formulas necesarias para poder aplicar la regresión logística_.
* _Formula **pclass-sex-age**._
* _Formula **pclass-age-fare**._
* _Formula **pclass-sex-age-fare**._
* _Formula **pclass-sex-age-sibSp-parch**._
* _Se crean los modelos en base a las formulas antes definidas utilizando **glm** (Generalized Linear Model) con **family:binomial** y el dataset de entrenamiento como **data**._
</div>
</div>
##### Ordenar por la deviance los 3 modelos creados en el punto 3)a) y el creado en el punto 2)a) y seleccionar el mejor modelo en términos de la deviance explicada.
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
model_evaluation <- models %>% mutate(glance = map(mod,glance))

model_comparison <- model_evaluation %>% unnest(glance) %>%
  mutate(perc_explained_dev = 1 - deviance/null.deviance) %>% 
  select(-c(model, df.null, AIC, BIC)) %>% 
  arrange(deviance)

model_comparison %>% select(expression:perc_explained_dev)
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _Los modelos que utilizan las variables **Pclass**, **Sex**y **Age** poseen valores similares de **deviance_explicada** y minimizan bien la *deviance*. Dentro ellos se destaca el modelo que tambien utiliza las variables **SibSp** y  **Parch** como el que mejor explica la **deviance**._

* _**Modelo seleccionado: pclass_sex_age_sibsp_parch**._
</div>
</div>

### Evaluación del modelo

##### Realizar el gráfico de curva ROC y obtener el AUC para el modelo elegido. Interpretar el gráfico.
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
models <- models %>% 
  mutate(pred= map(mod, augment, type.predict = "response"))

training_predictions = models %>% filter(model ==  'pclass_sex_age_sibsp_parch') %>% 
  unnest(pred)

datatable(training_predictions %>% select(Survived:.cooksd), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _Se agregan las estimaciones sobre los modelos._
* _Se realizan las estimaciones del modelo seleccionado sobre el dataset de entrenamiento._
* _Se pueden visualizar las predicciones del modelo seleccionado sobre el dataset de entrenamiento._
</div>
</div>
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
roc_training <- roc(response = training_predictions$Survived, predictor = training_predictions$.fitted)

ggroc(list(training=roc_training), size=1) + 
  geom_abline(slope = 1, intercept = 1, linetype='dashed') +
  theme_bw() + 
  labs(title='Curvas ROC', color='Modelo')
```

```{r message=FALSE}
print(paste('AUC: Modelo completo', round(roc_training$auc, 3)))
```

</div>
<div class = "col-md-4 blue">
**Observaciones**

* _**sensibilidad** = tasa de verdaderos positivos._
* _**especifidad** = tasa de falsos positivos._
* _El gráfico de la curva ROC analiza la evolución de la **sensibilidad**  vs la **especifidad** del modelo seleccionado a distintos umbrales de clasificación._
* _Los valores máximos de **especificidad** y **sensibilidad** se visualizan en valores conjuntos cercanos al 75%._
* _EL **AUC** del modelo seleccionado indica que el mismo clasifica correctamente a los sobrevivientes con una probabilidad del 84.8%._
</div>
</div>

##### Realizar un violin plot e interpretar.
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
ggplot(training_predictions, aes(x=Survived, y=.fitted, group=Survived, fill=factor(Survived))) + 
  geom_violin() +
  theme_bw() +
  guides(fill=FALSE) +
  labs(title='Violin plot', subtitle='Modelo pclass_sex_age_sibsp_parch', y='Predicted probability')
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _El gráfico de violín nos permite ver como se distribuyen la cantidad de observaciones por su clase real y la probabilidad que le asigna el modelo seleccionado._
* _Para las probabilidades inferiores a 0.25, clasifica correctamente los pasajeros que no sobrevivieron._
* _Para las probabilidades entre 0.25 y 0.5, clasifica de forma similar tanto a los sobrevivientes como a los no sobrevivientes._
* _Para las probabilidades superiores a 0.5 clasifica mejor a los sobrevivientes._
</div>
</div>
      
### Elección del punto corte

##### Sobre el dataset de VALIDACIÓN realizar un gráfico de Accuracy, Specificity, Recall y Precision en función del punto de corte.
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
selected_model <- glm(formulas_logit$pclass_sex_age_sibsp_parch, family = 'binomial', data = df_training)
validation_predictions = augment(x=selected_model, newdata=df_validation, type.predict='response') 
datatable(validation_predictions, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

```{r message=FALSE}
prediction_metrics <- function(cutoffs, predictions=validation_predictions) {
  table <- predictions %>% 
    mutate(predicted_class = if_else(.fitted > cutoffs, 1, 0) %>% as.factor(), Survived = factor(Survived))
  
  confusionMatrix(table$predicted_class, table$Survived, positive = "1") %>%
    tidy() %>%
    select(term, estimate) %>%
    filter(term %in% c('accuracy', 'sensitivity', 'specificity', 'precision')) %>%
    mutate(cutoff = cutoffs)
}

cutoffs = seq(0.01, 0.95, 0.01)

logit_pred_train = map_dfr(cutoffs, prediction_metrics) %>% 
  mutate(term=as.factor(term))

logit_pred_val = map_dfr(cutoffs, prediction_metrics, predictions = validation_predictions) %>% 
  mutate(term=as.factor(term))

ggplot(
  logit_pred_train, 
  aes(cutoff, estimate, group=term, color=term)) + 
  geom_line(size=1) +
  theme_bw() +
  labs(title= 'Accuracy, Sensitivity, Specificity y Precision', subtitle= 'Mejor Modelo en Entrenamiento', color="")

ggplot(
  logit_pred_val, 
  aes(cutoff, estimate, group=term, color=term)) + 
  geom_line(size=1) +
  theme_bw() +
  labs(title= 'Accuracy, Sensitivity, Specificity y Precision', subtitle= 'Mejor Modelo en Validación', color="")
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _Se crea el modelo seleccionado en base a la formula previamente creada utilizando **glm** (Generalized Linear Model) con **family:binomial** y el dataset de entrenamiento como **data**._
* _Se generan la predicciones al dataset de validación._
* _Se generan gráfico de **Accuracy, Specificity, Recall y Precision** para las predicciones en entrenamiento._
* _Se generan gráfico de **Accuracy, Specificity, Recall y Precision** para las predicciones en validación._

**Recordemos**

* *Accuracy*: ${\displaystyle \mathrm {ACC} ={\frac {\mathrm {TP} +\mathrm {TN} }{\mathrm {P} +\mathrm {N} }}={\frac {\mathrm {TP} +\mathrm {TN} }{\mathrm {TP} +\mathrm {TN} * +\mathrm {FP} +\mathrm {FN} }}}$
* *Precision*: ${\displaystyle \mathrm {PPV} ={\frac {\mathrm {TP} }{\mathrm {TP} +\mathrm {FP} }}=1-\mathrm {FDR} }$
* *Sensitivity*: ${\displaystyle \mathrm {TPR} ={\frac {\mathrm {TP} }{\mathrm {P} }}={\frac {\mathrm {TP} }{\mathrm {TP} +\mathrm {FN} }}=1-\mathrm {FNR} }$
* *Specificity*: ${\displaystyle \mathrm {TNR} ={\frac {\mathrm {TN} }{\mathrm {N} }}={\frac {\mathrm {TN} }{\mathrm {TN} +\mathrm {FP} }}=1-\mathrm {FPR} }$
</div>
</div>

##### Elegir un punto de corte y explicar su decisión.
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
ggplot(
  logit_pred_val %>% 
  filter(cutoff >= 0.39 & cutoff <= 0.44), 
  aes(cutoff, estimate, group=term, color=term)) + 
  geom_line(size=1) +
  theme_bw() +
  labs(title= 'Accuracy, Sensitivity, Specificity y Precision', subtitle= 'Modelo completo en Validación (rango de corte [0.39; 0.44])', color="") 
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _Se genera un corte entre [0.39; 0.44] en el gráfico de **Accuracy, Specificity, Recall y Precision** para lograr un mejor precisión en la búsqueda del punto de corte._
* _La mejor opción como punto de corte es en donde se cruzan las curvas de *accuracy*, *specificity* y *sensitivity*._
* _Este punto es **0.413**._
* _Para dicho punto se tienen valores de **accuracy**, **specificity** y **sensitivity** cercanos al 81% y un valor de *precision* cercano al 73%._
</div>
</div>
      
##### Obtener la matriz de confusión con el modelo y punto de corte elegidos. Interpretarla.
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
cutoff = 0.413

table <- validation_predictions %>% 
    mutate(predicted_class = if_else(.fitted > cutoff, 1, 0) %>% as.factor(), Survived = factor(Survived))
  
confusionMatrix(table$predicted_class, table$Survived, positive = "1")
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _El *accuracy* de modelo seleccionado es **80.45%**._ 
* _El *balanced accuracy*  del modelo seleccionado es **80.44%**._
* _La *sensitivity* del modelo seleccionado es **80.39%**._
* _La *specificity* del modelo seleccionado es **80.49%**._
* _El modelo seleccionado tiene valores elevados en las 4 cuatro métricas indicando que, al menos con el dataset de validación, es un modelo robusto_.
</div>
</div>
      

## DATASET DE TESTEO
### Evaluación del Modelo

##### Leer el archivo titanic_complete_test.csv y transformar las variables Survived, Pclass y Embarked a factor.
Cargamos nuestro dataset de titanic de test y convertimos nuestras variables **Survived**,  **Pclass** y **Embarked** como factor.
```{r message=FALSE}
df_test <- read_csv(here("/ds/titanic_complete_test.csv")) %>%
  mutate(Survived = factor(Survived), Pclass = factor(Pclass), Embarked = factor(Embarked))
glimpse(df)
```

##### Con el modelo y punto de corte elegidos clasificar a las personas del dataset de testing.
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
testing_predictions = augment(x=selected_model,  newdata=df_test,type.predict='response') 

testing_results <- testing_predictions %>% 
    mutate(predicted_class = if_else(.fitted > cutoff, 1, 0) %>% as.factor(),Survived = factor(Survived))

datatable(testing_results, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _Se realizan las estimaciones del modelo seleccionado sobre el dataset de testing._
* _Se pueden visualizar las predicciones del modelo seleccionado sobre el dataset de testing._
</div>
</div>

##### Obtener la matriz de confusión y comparar con la obtenida en el punto 5)c).
<div class = "row">
<div class = "col-md-8">
```{r message=FALSE}
confusionMatrix(testing_results$predicted_class, testing_results$Survived, positive = "1")
```
</div>
<div class = "col-md-4 blue">
**Observaciones**

* _El *accuracy* del modelo seleccionado es **74.16%**._ 
* _El *balanced accuracy*  del modelo seleccionado es **73.98%**._
* _La *sensitivity* del modelo seleccionado es **73.25%**._
* _La *specificity* del modelo seleccionado es **74.71%**._
* _Se observar que el modelo seleccionado aplicado al dataset de testing, si bien baja su performance con respecto al dataset de validación en validación, todavía mantiene cierta robustez_.
</div>
</div>

```{r}
sessionInfo()
```

